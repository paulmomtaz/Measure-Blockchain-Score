{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4c7ce46",
   "metadata": {},
   "source": [
    "## 1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import global_options\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pathlib import Path\n",
    "import stanza\n",
    "from stanza.server import CoreNLPClient\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d76b57",
   "metadata": {},
   "source": [
    "## 2 - Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2653c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(global_options.DATA_FOLDER, \"input\", \"Blockchain_FinancialTimes.csv\"))\n",
    "\n",
    "# Remove duplicates\n",
    "data = data.drop_duplicates(subset = 'Article title')\n",
    "\n",
    "# Combine columns into 'full_text' and clean up quotation marks\n",
    "data['full_text'] = data['Article title'] + ' ' + data['Article authors'] + ' ' + data['Full article text']\n",
    "\n",
    "# Select the desired columns\n",
    "data = data[['full_text']]\n",
    "\n",
    "# Replace the newline operator as space\n",
    "data['full_text'] = data['full_text'].str.replace('\\n', ' ', regex = False)\n",
    "\n",
    "#\n",
    "data['index'] = range(1, len(data)+1)\n",
    "\n",
    "data['full_text'] = data['full_text'].str.replace('â\\u0080\\u0098', \"‘\", regex=False)\n",
    "data['full_text'] = data['full_text'].str.replace('â\\u0080\\u0099', \"’\", regex=False)\n",
    "data['full_text'] = data['full_text'].str.replace('â\\u0080\\u009c', \"“\", regex=False)\n",
    "data['full_text'] = data['full_text'].str.replace('â\\u0080\\u009d', \"”\", regex=False)\n",
    "data['full_text'] = data['full_text'].str.replace('â\\u0080\\u0094', \"—\", regex=False)\n",
    "\n",
    "\n",
    "# Write to text files\n",
    "with open(Path(global_options.DATA_FOLDER, \"input\", \"documents.txt\"), \"w\") as file_docs:\n",
    "    for _, row in data.iterrows():\n",
    "        file_docs.write(f\"{row['full_text']}\\n\")\n",
    "        \n",
    "with open(Path(global_options.DATA_FOLDER, \"input\", \"document_ids.txt\"), \"w\") as file_docs:\n",
    "    for _, row in data.iterrows():\n",
    "        file_docs.write(f\"{row['index']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b231f2fb",
   "metadata": {},
   "source": [
    "## 3 - Run py files to expand the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13df9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 23:41:56 INFO: Writing properties to tmp file: corenlp_server-4ff0c3070de0458c.props\n",
      "2024-03-16 23:41:56 INFO: Starting server with command: java -Xmx8G -cp /Users/yuruchen/CoreNLP/* edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9004 -timeout 12000000 -threads 2 -maxCharLength 1000000 -quiet False -serverProperties corenlp_server-4ff0c3070de0458c.props -preload -outputFormat serialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 23:41:56.283366\n",
      "Processing line: 100.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[main] INFO CoreNLP - --- StanfordCoreNLPServer#main() called ---\n",
      "[main] INFO CoreNLP - Server default properties:\n",
      "\t\t\t(Note: unspecified annotator properties are English defaults)\n",
      "\t\t\tannotators = tokenize, ssplit, pos, lemma, ner, depparse\n",
      "\t\t\tinputFormat = text\n",
      "\t\t\tner.applyFineGrained = false\n",
      "\t\t\toutputFormat = serialized\n",
      "\t\t\tprettyPrint = false\n",
      "\t\t\tthreads = 2\n",
      "[main] INFO CoreNLP - Threads: 2\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator pos\n",
      "[main] INFO edu.stanford.nlp.tagger.maxent.MaxentTagger - Loading POS tagger from edu/stanford/nlp/models/pos-tagger/english-left3words-distsim.tagger ... done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.ie.AbstractSequenceClassifier - Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.time.JollyDayHolidays - Initializing JollyDayHoliday for SUTime from classpath edu/stanford/nlp/models/sutime/jollyday/Holidays_sutime.xml as sutime.binder.1.\n",
      "[main] INFO edu.stanford.nlp.time.TimeExpressionExtractorImpl - Using following SUTime rules: edu/stanford/nlp/models/sutime/defs.sutime.txt,edu/stanford/nlp/models/sutime/english.sutime.txt,edu/stanford/nlp/models/sutime/english.holidays.sutime.txt\n",
      "[main] INFO edu.stanford.nlp.pipeline.NERCombinerAnnotator - numeric classifiers: true; SUTime: true [no docDate]; fine grained: false\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator depparse\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Loading depparse model: edu/stanford/nlp/models/parser/nndep/english_UD.gz ... Time elapsed: 0.9 sec\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.Classifier - PreComputed 20000 vectors, elapsed Time: 0.62 sec\n",
      "[main] INFO edu.stanford.nlp.parser.nndep.DependencyParser - Initializing dependency parser ... done [1.5 sec].\n",
      "[main] INFO CoreNLP - Starting server...\n",
      "[main] INFO CoreNLP - StanfordCoreNLPServer listening at /0:0:0:0:0:0:0:0:9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-16 23:43:52.150247\n",
      "Processing line: 200.\n",
      "2024-03-16 23:46:11.234658\n",
      "Processing line: 300.\n",
      "2024-03-16 23:48:58.463076\n",
      "Processing line: 400.\n",
      "2024-03-17 00:04:15.659402\n",
      "Processing line: 500.\n",
      "2024-03-17 00:06:09.288758\n",
      "Processing line: 600.\n",
      "2024-03-17 00:11:24.049966\n",
      "Processing line: 700.\n",
      "2024-03-17 00:13:18.206309\n",
      "Processing line: 800.\n",
      "2024-03-17 00:15:39.783039\n",
      "Processing line: 900.\n",
      "2024-03-17 00:17:22.841182\n",
      "Processing line: 1000.\n",
      "2024-03-17 00:19:14.551950\n",
      "Processing line: 1100.\n",
      "2024-03-17 00:20:59.846853\n",
      "Processing line: 1200.\n",
      "2024-03-17 00:23:13.845903\n",
      "Processing line: 1300.\n",
      "2024-03-17 00:24:59.245850\n",
      "Processing line: 1400.\n",
      "2024-03-17 00:26:52.328737\n",
      "Processing line: 1500.\n",
      "2024-03-17 00:28:38.332137\n",
      "Processing line: 1600.\n",
      "2024-03-17 00:30:23.306562\n",
      "Processing line: 1700.\n",
      "2024-03-17 00:32:08.725556\n",
      "Processing line: 1800.\n",
      "2024-03-17 00:34:02.936031\n",
      "Processing line: 1900.\n",
      "2024-03-17 00:36:07.781849\n",
      "Processing line: 2000.\n",
      "2024-03-17 00:38:13.653082\n",
      "Processing line: 2100.\n",
      "2024-03-17 00:40:13.721858\n",
      "Processing line: 2200.\n",
      "2024-03-17 00:42:34.861887\n",
      "Processing line: 2300.\n",
      "2024-03-17 00:44:34.679917\n",
      "Processing line: 2400.\n",
      "2024-03-17 00:46:38.738056\n",
      "Processing line: 2500.\n",
      "2024-03-17 00:48:40.086601\n",
      "Processing line: 2600.\n",
      "2024-03-17 00:50:57.853120\n",
      "Processing line: 2700.\n",
      "2024-03-17 00:53:10.429895\n",
      "Processing line: 2800.\n",
      "2024-03-17 00:55:04.161368\n",
      "Processing line: 2900.\n",
      "2024-03-17 00:57:24.397916\n",
      "Processing line: 3000.\n",
      "2024-03-17 01:03:35.150815\n",
      "Processing line: 3100.\n",
      "2024-03-17 01:05:33.311524\n",
      "Processing line: 3200.\n",
      "2024-03-17 01:07:19.040520\n",
      "Processing line: 3300.\n",
      "2024-03-17 01:09:04.493004\n",
      "Processing line: 3400.\n",
      "2024-03-17 01:10:55.065380\n",
      "Processing line: 3500.\n",
      "2024-03-17 01:12:21.918172\n",
      "Processing line: 3600.\n",
      "2024-03-17 01:13:46.219693\n",
      "Processing line: 3700.\n",
      "2024-03-17 01:15:31.327399\n",
      "Processing line: 3800.\n",
      "2024-03-17 01:16:57.349466\n",
      "Processing line: 3900.\n",
      "2024-03-17 01:18:22.052729\n",
      "Processing line: 4000.\n",
      "2024-03-17 01:20:07.870150\n",
      "Processing line: 4100.\n",
      "2024-03-17 01:21:27.125540\n",
      "Processing line: 4200.\n",
      "2024-03-17 01:22:33.080210\n",
      "Processing line: 4300.\n",
      "2024-03-17 01:24:36.244912\n",
      "Processing line: 4400.\n",
      "2024-03-17 01:26:27.934410\n",
      "Processing line: 4500.\n",
      "2024-03-17 01:28:20.654770\n",
      "Processing line: 4600.\n",
      "2024-03-17 01:30:06.969140\n",
      "Processing line: 4700.\n",
      "2024-03-17 01:31:58.011786\n",
      "Processing line: 4800.\n",
      "2024-03-17 01:33:36.194866\n",
      "Processing line: 4900.\n",
      "2024-03-17 01:35:30.657064\n",
      "Processing line: 5000.\n",
      "2024-03-17 01:37:19.508724\n",
      "Processing line: 5100.\n",
      "2024-03-17 01:39:08.708136\n",
      "Processing line: 5200.\n",
      "2024-03-17 01:41:44.125566\n",
      "Processing line: 5300.\n",
      "2024-03-17 01:44:28.900516\n",
      "Processing line: 5400.\n",
      "2024-03-17 01:46:42.830294\n",
      "Processing line: 5500.\n",
      "2024-03-17 01:49:24.344087\n",
      "Processing line: 5600.\n",
      "2024-03-17 01:51:33.226273\n",
      "Processing line: 5700.\n",
      "2024-03-17 01:53:29.307068\n",
      "Processing line: 5800.\n",
      "2024-03-17 01:55:56.976121\n",
      "Processing line: 5900.\n",
      "2024-03-17 01:58:06.503643\n",
      "Processing line: 6000.\n",
      "2024-03-17 02:00:04.286276\n",
      "Processing line: 6100.\n",
      "2024-03-17 02:02:32.702867\n",
      "Processing line: 6200.\n",
      "2024-03-17 02:04:27.459421\n",
      "Processing line: 6300.\n",
      "2024-03-17 02:06:20.985355\n",
      "Processing line: 6400.\n",
      "2024-03-17 02:08:23.202889\n",
      "Processing line: 6500.\n",
      "2024-03-17 02:10:14.889695\n",
      "Processing line: 6600.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Thread-0] INFO CoreNLP - CoreNLP Server is shutting down.\n"
     ]
    }
   ],
   "source": [
    "%run parse_parallel.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73282975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-17 02:10:50.042162\n",
      "Processing line: 200000.\n",
      "2024-03-17 02:10:57.907009\n",
      "Processing line: 400000.\n",
      "2024-03-17 02:11:03.644445\n",
      "Training phraser...\n",
      "DEBUG:gensim.models.word2vec:single file given as source, rather than a directory of files\n",
      "DEBUG:gensim.models.word2vec:consider using models.word2vec.LineSentence for a single file\n",
      "INFO:gensim.models.word2vec:files read into PathLineSentences:data/processed/unigram/documents.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                | 0/341135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:reading file data/processed/unigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/unigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.phrases:PROGRESS: at sentence #0, processed 0 words and 0 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▊                                 | 8350/341135 [00:00<00:03, 83485.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #10000, processed 90818 words and 70981 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|█▋                               | 17644/341135 [00:00<00:03, 89040.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #20000, processed 185424 words and 131273 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██▌                              | 26549/341135 [00:00<00:03, 87588.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #30000, processed 285132 words and 192197 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███▍                             | 35311/341135 [00:00<00:03, 87415.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #40000, processed 378659 words and 243789 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|████▎                            | 44055/341135 [00:00<00:03, 85331.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #50000, processed 487333 words and 303281 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█████                            | 52597/341135 [00:00<00:03, 80807.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #60000, processed 595919 words and 362199 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████▋                          | 68588/341135 [00:00<00:03, 77015.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #70000, processed 706287 words and 419365 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|███████▍                         | 76309/341135 [00:00<00:03, 75597.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #80000, processed 809934 words and 468445 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████▏                        | 84452/341135 [00:01<00:03, 77306.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #90000, processed 913909 words and 514585 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|█████████▋                       | 99877/341135 [00:01<00:03, 76362.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #100000, processed 1017279 words and 561666 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████                      | 107672/341135 [00:01<00:03, 76828.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #110000, processed 1121098 words and 610417 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|██████████▊                     | 115361/341135 [00:01<00:02, 75378.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #120000, processed 1231387 words and 663131 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████▌                    | 122907/341135 [00:01<00:02, 74105.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #130000, processed 1342720 words and 714610 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████▉                   | 137633/341135 [00:01<00:02, 69794.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #140000, processed 1446361 words and 759740 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████▌                  | 144677/341135 [00:01<00:02, 69624.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #150000, processed 1561165 words and 808616 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████▉                 | 158581/341135 [00:02<00:02, 67943.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #160000, processed 1679738 words and 863039 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████▌                | 165396/341135 [00:02<00:02, 66678.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #170000, processed 1794559 words and 913802 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████▊               | 178801/341135 [00:02<00:02, 66487.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #180000, processed 1911366 words and 964164 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████████████████▍              | 185458/341135 [00:02<00:02, 66082.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #190000, processed 2026809 words and 1015071 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|██████████████████▋             | 199287/341135 [00:02<00:02, 67671.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #200000, processed 2136251 words and 1058754 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████▎            | 206059/341135 [00:02<00:02, 67151.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #210000, processed 2253258 words and 1106543 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|████████████████████▌           | 219553/341135 [00:03<00:01, 65624.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #220000, processed 2365538 words and 1156779 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████▏          | 226217/341135 [00:03<00:01, 65920.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #230000, processed 2481135 words and 1205209 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████▍         | 239410/341135 [00:03<00:01, 65477.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #240000, processed 2596184 words and 1251523 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████████████████████         | 246231/341135 [00:03<00:01, 66283.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #250000, processed 2705839 words and 1296158 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████▋        | 253091/341135 [00:03<00:01, 66968.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #260000, processed 2804425 words and 1336847 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████▏      | 268231/341135 [00:03<00:01, 71128.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #270000, processed 2908915 words and 1380207 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████▊      | 275348/341135 [00:03<00:01, 58302.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #280000, processed 3019173 words and 1425004 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████     | 288704/341135 [00:04<00:00, 62206.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #290000, processed 3130337 words and 1471063 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|███████████████████████████▋    | 295396/341135 [00:04<00:00, 63519.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #300000, processed 3232514 words and 1514984 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████▍   | 302940/341135 [00:04<00:00, 66911.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #310000, processed 3329968 words and 1555480 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████████████████████████▊  | 318141/341135 [00:04<00:00, 71552.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #320000, processed 3424186 words and 1594182 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████▌ | 325377/341135 [00:04<00:00, 71047.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #330000, processed 3533407 words and 1636374 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████▊| 339541/341135 [00:04<00:00, 68726.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #340000, processed 3643472 words and 1681467 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████▉| 340328/341135 [00:04<00:00, 70302.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collected 1683026 word types from a corpus of 3647052 words (unigram + bigrams) and 340328 sentences\n",
      "INFO:gensim.models.phrases:using 1683026 counts as vocab in Phrases<0 vocab, min_count=10, threshold=10, max_vocab_size=40000000>\n",
      "INFO:gensim.utils:saving Phrases object under models/phrases/bigram.mod, separately None\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/phrases/bigram.mod', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saved models/phrases/bigram.mod\n",
      "INFO:gensim.utils:loading Phrases object from models/phrases/bigram.mod\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/phrases/bigram.mod', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:loaded models/phrases/bigram.mod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 341135/341135 [00:09<00:00, 34364.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-17 02:11:22.119791\n",
      "Training phraser...\n",
      "DEBUG:gensim.models.word2vec:single file given as source, rather than a directory of files\n",
      "DEBUG:gensim.models.word2vec:consider using models.word2vec.LineSentence for a single file\n",
      "INFO:gensim.models.word2vec:files read into PathLineSentences:data/processed/bigram/documents.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                | 0/341135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:reading file data/processed/bigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/bigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.phrases:PROGRESS: at sentence #0, processed 0 words and 0 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▉                                 | 9843/341135 [00:00<00:03, 98426.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #10000, processed 85724 words and 71988 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█▉                               | 19686/341135 [00:00<00:03, 95824.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #20000, processed 174994 words and 134126 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|██▊                              | 29274/341135 [00:00<00:03, 91812.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #30000, processed 269372 words and 197132 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|███▋                             | 38639/341135 [00:00<00:03, 92511.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #40000, processed 357696 words and 250723 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|████▋                            | 47903/341135 [00:00<00:03, 89210.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #50000, processed 459978 words and 312823 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████▍                           | 56846/341135 [00:00<00:03, 84084.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #60000, processed 563198 words and 374122 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████▎                          | 65305/341135 [00:00<00:03, 82036.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #70000, processed 667182 words and 433901 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|███████                          | 73541/341135 [00:00<00:03, 80293.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #80000, processed 764895 words and 485499 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|████████▋                        | 89966/341135 [00:01<00:03, 81099.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #90000, processed 863019 words and 534078 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|█████████▍                       | 98089/341135 [00:01<00:02, 81108.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #100000, processed 960968 words and 583360 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████▉                      | 106209/341135 [00:01<00:02, 80437.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #110000, processed 1059200 words and 634397 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████▋                     | 114259/341135 [00:01<00:02, 78498.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #120000, processed 1163858 words and 689745 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████▏                   | 129670/341135 [00:01<00:02, 74730.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #130000, processed 1269436 words and 743735 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████▉                   | 137394/341135 [00:01<00:02, 75451.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #140000, processed 1367658 words and 791246 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████▌                  | 144955/341135 [00:01<00:02, 73113.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #150000, processed 1475613 words and 842960 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|██████████████▉                 | 159467/341135 [00:02<00:02, 70995.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #160000, processed 1588420 words and 900222 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████▋                | 166577/341135 [00:02<00:02, 69750.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #170000, processed 1698164 words and 953727 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████▎               | 173560/341135 [00:02<00:02, 68670.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #180000, processed 1809218 words and 1006892 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████████████████▌              | 187282/341135 [00:02<00:02, 68355.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #190000, processed 1918810 words and 1061152 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████▏             | 194553/341135 [00:02<00:02, 69630.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #200000, processed 2022278 words and 1107628 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|███████████████████▌            | 208482/341135 [00:02<00:01, 69070.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #210000, processed 2133451 words and 1158398 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████▏           | 215392/341135 [00:02<00:01, 68114.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #220000, processed 2240749 words and 1211050 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|█████████████████████▌          | 229508/341135 [00:03<00:01, 68694.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #230000, processed 2350578 words and 1262182 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████████████████████▏         | 236381/341135 [00:03<00:01, 68380.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #240000, processed 2459561 words and 1310999 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████▊         | 243222/341135 [00:03<00:01, 68016.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #250000, processed 2563859 words and 1357859 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████▏       | 257771/341135 [00:03<00:01, 70567.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #260000, processed 2658006 words and 1400523 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|████████████████████████▊       | 264831/341135 [00:03<00:01, 65996.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #270000, processed 2757693 words and 1446099 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|██████████████████████████      | 278450/341135 [00:04<00:02, 29299.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #280000, processed 2862999 words and 1493208 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████▋     | 284863/341135 [00:04<00:01, 34631.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #290000, processed 2969503 words and 1541662 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████▉    | 297576/341135 [00:04<00:01, 42801.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #300000, processed 3067956 words and 1587564 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████████████████████████▌   | 305113/341135 [00:04<00:00, 49844.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #310000, processed 3161483 words and 1629947 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████▎  | 312475/341135 [00:04<00:00, 55456.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #320000, processed 3251841 words and 1670429 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████▋ | 327240/341135 [00:04<00:00, 62900.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #330000, processed 3355540 words and 1715030 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|███████████████████████████████▎| 334130/341135 [00:05<00:00, 64396.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:PROGRESS: at sentence #340000, processed 3460730 words and 1762368 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████▉| 340328/341135 [00:05<00:00, 66188.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.phrases:collected 1764008 word types from a corpus of 3464175 words (unigram + bigrams) and 340328 sentences\n",
      "INFO:gensim.models.phrases:using 1764008 counts as vocab in Phrases<0 vocab, min_count=10, threshold=10, max_vocab_size=40000000>\n",
      "INFO:gensim.utils:saving Phrases object under models/phrases/trigram.mod, separately None\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/phrases/trigram.mod', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:saved models/phrases/trigram.mod\n",
      "INFO:gensim.utils:loading Phrases object from models/phrases/trigram.mod\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/phrases/trigram.mod', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:loaded models/phrases/trigram.mod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 341135/341135 [00:09<00:00, 34441.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-17 02:11:40.517178\n",
      "Training w2v model...\n",
      "DEBUG:gensim.models.word2vec:single file given as source, rather than a directory of files\n",
      "DEBUG:gensim.models.word2vec:consider using models.word2vec.LineSentence for a single file\n",
      "INFO:gensim.models.word2vec:files read into PathLineSentences:data/processed/trigram/documents.txt\n",
      "INFO:gensim.models.word2vec:collecting all words and their counts\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #10000, processed 84323 words, keeping 13585 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #20000, processed 172205 words, keeping 21538 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #30000, processed 265215 words, keeping 28881 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #40000, processed 352053 words, keeping 34665 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #50000, processed 452580 words, keeping 41155 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #60000, processed 554428 words, keeping 47603 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #70000, processed 656474 words, keeping 53606 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #80000, processed 752456 words, keeping 58164 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #90000, processed 848966 words, keeping 62412 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #100000, processed 945426 words, keeping 66841 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #110000, processed 1042104 words, keeping 71588 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #120000, processed 1145189 words, keeping 76846 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #130000, processed 1249068 words, keeping 81996 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #140000, processed 1345834 words, keeping 86203 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #150000, processed 1451877 words, keeping 90755 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #160000, processed 1563161 words, keeping 96554 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #170000, processed 1671745 words, keeping 101162 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #180000, processed 1781248 words, keeping 106174 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #190000, processed 1889588 words, keeping 110939 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #200000, processed 1991474 words, keeping 115243 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #210000, processed 2101208 words, keeping 119834 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #220000, processed 2207282 words, keeping 124931 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #230000, processed 2315670 words, keeping 129654 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #240000, processed 2423111 words, keeping 134073 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #250000, processed 2525891 words, keeping 138620 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #260000, processed 2618779 words, keeping 142545 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #270000, processed 2717120 words, keeping 146823 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #280000, processed 2820989 words, keeping 151450 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #290000, processed 2926259 words, keeping 156270 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #300000, processed 3023847 words, keeping 160414 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #310000, processed 3116379 words, keeping 164218 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #320000, processed 3205726 words, keeping 168098 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #330000, processed 3307790 words, keeping 172307 word types\n",
      "INFO:gensim.models.word2vec:PROGRESS: at sentence #340000, processed 3411571 words, keeping 176845 word types\n",
      "INFO:gensim.models.word2vec:collected 176992 word types from a corpus of 3414983 raw words and 340328 sentences\n",
      "INFO:gensim.models.word2vec:Loading a fresh vocabulary\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 retains 29311 unique words (16% of original 176992, drops 147681)\n",
      "INFO:gensim.models.word2vec:effective_min_count=5 leaves 3217632 word corpus (94% of original 3414983, drops 197351)\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 176992 items\n",
      "INFO:gensim.models.word2vec:sample=0.001 downsamples 21 most-common words\n",
      "INFO:gensim.models.word2vec:downsampling leaves estimated 2739359 word corpus (85.1% of prior 3217632)\n",
      "INFO:gensim.models.base_any2vec:estimated required memory for 29311 words and 300 dimensions: 85001900 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.models.base_any2vec:training model with 2 workers on 29311 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 26.16% examples, 672814 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 49.06% examples, 656324 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 72.35% examples, 664843 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 1 - PROGRESS: at 96.96% examples, 660889 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 1 : training on 3414983 raw words (2740099 effective words) took 4.1s, 662607 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 24.95% examples, 644804 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 42.11% examples, 551060 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 64.04% examples, 582592 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 2 - PROGRESS: at 88.92% examples, 607094 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 172 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 170 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 2 : training on 3414983 raw words (2739123 effective words) took 4.5s, 615295 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 24.00% examples, 623428 words/s, in_qsize 3, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 47.98% examples, 638858 words/s, in_qsize 3, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 71.49% examples, 655307 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 3 - PROGRESS: at 96.08% examples, 651459 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 170 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 172 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 3 : training on 3414983 raw words (2739900 effective words) took 4.2s, 654535 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 17.48% examples, 444111 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 41.50% examples, 542125 words/s, in_qsize 3, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 64.41% examples, 584755 words/s, in_qsize 4, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 4 - PROGRESS: at 88.29% examples, 600340 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 4 : training on 3414983 raw words (2739454 effective words) took 4.5s, 610524 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 24.64% examples, 633657 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 49.34% examples, 660104 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 71.49% examples, 657120 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 5 - PROGRESS: at 87.95% examples, 602795 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 5 : training on 3414983 raw words (2739895 effective words) took 4.5s, 605186 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 26.16% examples, 675758 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 49.34% examples, 659891 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 72.92% examples, 666791 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 6 - PROGRESS: at 97.80% examples, 661788 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 6 : training on 3414983 raw words (2739419 effective words) took 4.1s, 663701 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 24.64% examples, 633192 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 49.60% examples, 660682 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 72.35% examples, 658206 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 7 - PROGRESS: at 98.10% examples, 663306 words/s, in_qsize 3, out_qsize 1\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 7 : training on 3414983 raw words (2739592 effective words) took 4.1s, 666171 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 23.70% examples, 609821 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 41.78% examples, 547579 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 62.98% examples, 573776 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 8 - PROGRESS: at 86.11% examples, 589718 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 8 : training on 3414983 raw words (2739094 effective words) took 4.6s, 600728 effective words/s\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 24.95% examples, 636344 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 49.34% examples, 656048 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 71.49% examples, 651529 words/s, in_qsize 4, out_qsize 1\n",
      "INFO:gensim.models.base_any2vec:EPOCH 9 - PROGRESS: at 97.52% examples, 660534 words/s, in_qsize 4, out_qsize 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 9 : training on 3414983 raw words (2739209 effective words) took 4.1s, 663342 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 16.35% examples, 413013 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 41.50% examples, 546946 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 63.51% examples, 579975 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 10 - PROGRESS: at 88.29% examples, 602806 words/s, in_qsize 3, out_qsize 1\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 10 : training on 3414983 raw words (2739721 effective words) took 4.5s, 605670 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 26.46% examples, 679541 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 49.86% examples, 665983 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 72.04% examples, 660561 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 11 - PROGRESS: at 89.55% examples, 611527 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 11 : training on 3414983 raw words (2739577 effective words) took 4.4s, 617840 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 24.32% examples, 626973 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 48.78% examples, 651638 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 71.21% examples, 653631 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 12 - PROGRESS: at 95.79% examples, 651254 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 12 : training on 3414983 raw words (2739739 effective words) took 4.2s, 654839 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 26.16% examples, 672153 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 49.34% examples, 658565 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 65.21% examples, 592752 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 13 - PROGRESS: at 88.92% examples, 605982 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 13 : training on 3414983 raw words (2738819 effective words) took 4.5s, 614288 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 24.64% examples, 633270 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 49.34% examples, 658486 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 71.78% examples, 657850 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 14 - PROGRESS: at 97.52% examples, 662348 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 14 : training on 3414983 raw words (2739416 effective words) took 4.1s, 665324 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 24.95% examples, 639719 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 40.94% examples, 533858 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 62.73% examples, 568127 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 15 - PROGRESS: at 87.66% examples, 596524 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 170 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 172 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.base_any2vec:EPOCH - 15 : training on 3414983 raw words (2739552 effective words) took 4.6s, 600695 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 25.87% examples, 663465 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 49.34% examples, 657414 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 71.49% examples, 655017 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 16 - PROGRESS: at 96.96% examples, 659011 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 16 : training on 3414983 raw words (2739729 effective words) took 4.5s, 614366 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 24.32% examples, 627684 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 49.06% examples, 657308 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 71.49% examples, 654750 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 17 - PROGRESS: at 96.67% examples, 654617 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 17 : training on 3414983 raw words (2738877 effective words) took 4.2s, 656448 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 25.87% examples, 666210 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 49.34% examples, 659127 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 70.38% examples, 617344 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 18 - PROGRESS: at 92.66% examples, 609896 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 18 : training on 3414983 raw words (2739156 effective words) took 4.4s, 616466 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 24.95% examples, 646735 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 49.34% examples, 662420 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 71.49% examples, 657420 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 19 - PROGRESS: at 97.26% examples, 663170 words/s, in_qsize 3, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 170 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 172 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 19 : training on 3414983 raw words (2739681 effective words) took 4.1s, 665156 effective words/s\n",
      "INFO:gensim.models.word2vec:reading file data/processed/trigram/documents.txt\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'data/processed/trigram/documents.txt', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 24.64% examples, 631875 words/s, in_qsize 4, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 43.45% examples, 561521 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 64.68% examples, 581393 words/s, in_qsize 3, out_qsize 0\n",
      "INFO:gensim.models.base_any2vec:EPOCH 20 - PROGRESS: at 89.55% examples, 603006 words/s, in_qsize 4, out_qsize 0\n",
      "DEBUG:gensim.models.base_any2vec:job loop exiting, total 342 jobs\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.base_any2vec:worker exiting, processed 171 jobs\n",
      "INFO:gensim.models.base_any2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.base_any2vec:EPOCH - 20 : training on 3414983 raw words (2739581 effective words) took 4.5s, 604953 effective words/s\n",
      "INFO:gensim.models.base_any2vec:training on a 68299660 raw words (54789633 effective words) took 86.7s, 631649 effective words/s\n",
      "INFO:gensim.utils:saving Word2Vec object under models/w2v/w2v.mod, separately None\n",
      "INFO:gensim.utils:not storing attribute vectors_norm\n",
      "INFO:gensim.utils:not storing attribute cum_table\n",
      "DEBUG:smart_open.smart_open_lib:{'uri': 'models/w2v/w2v.mod', 'mode': 'wb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'compression': 'infer_from_extension', 'transport_params': None}\n",
      "INFO:gensim.utils:saved models/w2v/w2v.mod\n"
     ]
    }
   ],
   "source": [
    "%run clean_and_train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cefdb53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size in the w2v model: 29311\n",
      "Dictionary created. \n",
      "Dictionary deduplicated. \n",
      "Dictionary saved at outputs/dict/expanded_dict.csv\n"
     ]
    }
   ],
   "source": [
    "%run create_dict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf2d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
